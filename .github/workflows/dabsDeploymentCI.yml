
# This workflow validates, deploys, and runs the specified bundle
# within a pre-production target named "qa".
name: "DABS & PyDABS Continuous Integration"

# Ensure that only a single job or workflow using the same concurrency group
# runs at a time.
concurrency:
  group: dabsci
  cancel-in-progress: true
# Trigger this workflow whenever a pull request is opened against the repo's
# main branch or an existing pull request's head branch is updated.
on:
  pull_request:
    types:
      - opened
      - synchronize
    branches:
      - main

jobs:
  # Used by the "pipeline_update" job to deploy the bundle.
  # Bundle validation is automatically performed as part of this deployment.
  # If validation fails, this workflow fails.
  stagingbuild:
    name: "Validate Bundle in test"
    runs-on: ubuntu-latest
    environment: test
    steps:
      # Check out this repo, so that this workflow can access it.
      - uses: actions/checkout@v3
      - name: setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11' # install the python version needed

      # Download the Databricks CLI.
      # See https://github.com/databricks/setup-cli
      - uses: databricks/setup-cli@main

      - run: pip3 install wheel

      # Deploy the bundle to the "qa" target as defined
      # in the bundle's settings file.
      - run: databricks bundle validate --var="warehouse_id=${{ vars.BUNDLE_VAR_warehouse_id }},node_type=${{ vars.BUNDLE_VAR_node_type }},git_url=${{ vars.git_url }}" -t test
        working-directory: .
        env:
          DATABRICKS_BUNDLE_ENV: ${{ vars.DATABRICKS_BUNDLE_ENV }}
          DATABRICKS_HOST: ${{ vars.DATABRICKS_HOST }}
          BUNDLE_VAR_warehouse_id: ${{ vars.BUNDLE_VAR_warehouse_id }}
          BUNDLE_VAR_node_type: ${{ vars.BUNDLE_VAR_node_type }}
          ARM_TENANT_ID: ${{ vars.TENANT_ID }}
          ARM_CLIENT_ID: ${{ vars.CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}


  prodbuild:
    name: "Validate Bundle in Prod"
    runs-on: ubuntu-latest
    environment: prod
    steps:
      # Check out this repo, so that this workflow can access it.
      - uses: actions/checkout@v3
      - name: setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11' # install the python version needed

      # Download the Databricks CLI.
      # See https://github.com/databricks/setup-cli
      - uses: databricks/setup-cli@main

      - run: pip3 install wheel

      # Deploy the bundle to the "qa" target as defined
      # in the bundle's settings file.
      - run: databricks bundle validate --var="warehouse_id=${{ vars.BUNDLE_VAR_warehouse_id }},node_type=${{ vars.BUNDLE_VAR_node_type }},git_url=${{ vars.git_url }}" -t prod
        working-directory: .
        env:
          DATABRICKS_BUNDLE_ENV: ${{ vars.DATABRICKS_BUNDLE_ENV }}
          DATABRICKS_HOST: ${{ vars.DATABRICKS_HOST }}
          BUNDLE_VAR_warehouse_id: ${{ vars.BUNDLE_VAR_warehouse_id }}
          BUNDLE_VAR_node_type: ${{ vars.BUNDLE_VAR_node_type }}
          ARM_TENANT_ID: ${{ vars.TENANT_ID }}
          ARM_CLIENT_ID: ${{ vars.CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}



